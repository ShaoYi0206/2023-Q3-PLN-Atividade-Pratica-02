{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaoYi0206/2023-Q3-PLN-Atividade-Pratica-02/blob/main/C%C3%B3pia_de_2023_Q3_PLN_ATIVIDADE_PR%C3%81TICA_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 02 [Extração e Pré-processamento de Dados + Expressões Regulares]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 02** deve ser feita utilizando o **Google Colab** com uma conta\n",
        "sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/83JggUJ1mhgWviEaA\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia 16/10 (segunda-feira) APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Antonio Kung"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: ` 3\n",
        "\n",
        "`Segundo capítulo:` 22\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` para identificar ERROS em 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        "Os capítulos devem ser selecionados na seguinte planilha:\n",
        "\n",
        "https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**DICA:** Por favor, insira o seu nome ou da sua equipe na ordem definida na planilha. Por exemplo, se a linha correspondente ao o GRUPO 5 já foi preenchida, a próxima equipe (GRUPO 6) deverá ser informada na próxima linha da planilha.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TIPOS DE ERROS**\n",
        "---\n"
      ],
      "metadata": {
        "id": "eD_AJQhrwJQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: consulta feita no ChatGPT\n",
        ">\n",
        "\n",
        "Um `programa Python` que utilize `expressões regulares` pode ajudar a identificar vários **tipos de erros** comuns em **livros**, especialmente erros de formatação e problemas relacionados à consistência do texto. Aqui estão alguns exemplos de erros comuns que podem ser identificados usando expressões regulares:\n",
        "\n",
        "* Erros de gramática e ortografia: erros de digitação, concordância verbal e nominal, uso incorreto de pontuação e outros erros gramaticais.\n",
        "\n",
        "* Problemas de formatação: você pode usar expressões regulares para encontrar erros de formatação, como espaços em excesso, tabulações inadequadas ou alinhamentos inconsistentes.\n",
        "\n",
        "* Abreviações e acrônimos: você pode usar expressões regulares para encontrar abreviações ou acrônimos que não foram definidos ou explicados anteriormente no texto.\n",
        "\n",
        "* Citações e referências: expressões regulares podem ser úteis para localizar citações ou referências que precisam de formatação especial.\n",
        "\n",
        "* OUTROS TIPOS DE ERROS: não considerem apenas os tipos de erros citados acima.\n",
        "\n",
        "\n",
        "**IMPORTANTE:** Lembre-se de que expressões regulares podem ser poderosas, mas também complexas. Dependendo da complexidade dos erros que você deseja identificar, pode ser necessário ajustar as expressões regulares de acordo com as características específicas do seu texto. Além disso, é importante ter em mente que as expressões regulares podem não ser a melhor ferramenta para todos os tipos de erros em livros, especialmente problemas mais contextuais ou semânticos, que podem exigir abordagens de PLN mais avançadas.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gz0DTI0KYmn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A equipe que **realizar mais testes** e/ou **identificar mais erros** terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30). Os testes e possíveis erros devem ser contabizados de maneira separada.\n",
        "\n",
        ">\n",
        "\n",
        "Além disso, **por se tratar de um livro**, há um teste importante que deve ser feito. Lembre-se que o teste deve ser feito utilizando expressões regulares. A equipe que realizar esse teste, mesmo que o erro não ocorra nos capítulos selecionados, terá o peso diminuido na AVALIAÇÃO (Prova Escrita) em **25%** (caindo de 40 para 30).\n",
        "\n",
        "> A equipe pode considerar outros capítulos do livro para tentar identificar esse tipo de erro.\n",
        "\n",
        "**Se for a mesma equipe, o peso da avaliação será reduzido em 50% (caindo de 40 para 20)**.\n",
        "\n",
        ">\n",
        "\n",
        "**IMPORTANTE**: a diminuição no peso da AVALIAÇÃO será aplicado para todos os membros da equipe. Esse critério será aplicado apenas para uma equipe, considerando como critério de desempate a equipe que entregar primeiro a atividade no formulário.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "user_agents_list = [\n",
        "    'Mozilla/5.0 (Linux; Android 13; SM-S901B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',\n",
        "    'Mozilla/5.0 (Linux; Android 13; SM-A515F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',\n",
        "    'Mozilla/5.0 (Linux; Android 13; Pixel 6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Mobile Safari/537.36',\n",
        "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'\n",
        "]\n",
        "\n",
        "url_cap3 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte2/cap3/cap3.html'\n",
        "url_cap22 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte9/cap22/cap22.html'\n",
        "\n",
        "response3 = requests.get(url_cap3, headers={'User-Agent': random.choice(user_agents_list)})\n",
        "\n",
        "response22 = requests.get(url_cap22, headers={'User-Agent': random.choice(user_agents_list)})\n",
        "\n",
        "if response3.status_code == 200 and response22.status_code:\n",
        "  print('Conexao bem-sucedida')\n"
      ],
      "metadata": {
        "id": "RyUailD5vi9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e487015f-0d8e-4f10-b3d2-f4bef9c5a4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conexao bem-sucedida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker"
      ],
      "metadata": {
        "id": "lrhNVQqAy3_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capitulo 3\n",
        "content3 = response3.text\n",
        "soup3 = BeautifulSoup(content3, 'html.parser')\n",
        "text3 = soup3.get_text()\n",
        "\n",
        "# Capitulo 22\n",
        "content22 = response22.text\n",
        "soup22 = BeautifulSoup(content22, 'html.parser')\n",
        "text22 = soup22.get_text()"
      ],
      "metadata": {
        "id": "ww7H8z158eh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text3)"
      ],
      "metadata": {
        "id": "nsC1E0PkNt90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar erros de formatacao\n",
        "padrao_formatacao = r'[^\\x00-\\x7F]+'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_formatacao3 = re.findall(padrao_formatacao, text3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erros de formatacao: {len(erro_formatacao3)}')\n",
        "\n",
        "# Capitulo 22\n",
        "erro_formatacao22 = re.findall(padrao_formatacao, text22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erros de formatacao: {len(erro_formatacao22)}')"
      ],
      "metadata": {
        "id": "gyKrldAbnDJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e984e3b1-09a3-47f4-f0c3-d220ee993b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitulo 3: Quantidade de erros de formatacao: 1906\n",
            "Capitulo 22: Quantidade de erros de formatacao: 1193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar erros de espacamento\n",
        "padrao_espacamento = r'\\s{2,}'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_espacamento3 = re.findall(padrao_espacamento, text3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erros de espacamento: {len(erro_espacamento3)}')\n",
        "\n",
        "# Capitulo 3\n",
        "erro_espacamento22 = re.findall(padrao_espacamento, text22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erros de espacamento: {len(erro_espacamento22)}')"
      ],
      "metadata": {
        "id": "xT6jljYcnqMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc9e947-ef6c-4cac-ed85-6166fc53fa5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitulo 3: Quantidade de erros de espacamento: 324\n",
            "Capitulo 22: Quantidade de erros de espacamento: 154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar errro de tabulacoes\n",
        "padrao_tabulacao = r'(?<!\\t)\\t+|^\\t+'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_tabulacao3 = re.findall(padrao_tabulacao, text3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erros de tabulacao: {len(erro_tabulacao3)}')\n",
        "\n",
        "# Capitulo 22\n",
        "erro_tabulacao22 = re.findall(padrao_tabulacao, text22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erros de tabulacao: {len(erro_tabulacao22)}')"
      ],
      "metadata": {
        "id": "nAkbYfADa2lX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf8aae3-be0b-4e2b-cca4-e1fa1227c307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitulo 3: Quantidade de erros de tabulacao: 0\n",
            "Capitulo 22: Quantidade de erros de tabulacao: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar erro de alinhamento\n",
        "padrao_alinhamento = r'^(?:(?:(\\t* +)|( +\\t*))*)\\S'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_alinhamento3 = re.findall(padrao_alinhamento, text3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erros de alinhamento: {len(erro_alinhamento3)}')\n",
        "\n",
        "# Capitulo 22\n",
        "erro_alinhamento22 = re.findall(padrao_alinhamento, text22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erros de alinhamento: {len(erro_alinhamento22)}')"
      ],
      "metadata": {
        "id": "TNmmiuvobPZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae6b3f9-a4da-4090-e296-ac71571bf4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capitulo 3: Quantidade de erros de alinhamento: 0\n",
            "Capitulo 22: Quantidade de erros de alinhamento: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrar palavras duplicadas\n",
        "padrao_duplicadas = r'\\b(\\w+)\\s+\\1\\b'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_duplicadas3 = re.findall(padrao_duplicadas, text3)\n",
        "\n",
        "print(erro_duplicadas3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erro de duplicadas: {len(erro_duplicadas3)}')\n",
        "\n",
        "# Capitulo 22\n",
        "erro_duplicadas22 = re.findall(padrao_duplicadas, text22)\n",
        "\n",
        "print(erro_duplicadas22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erro de duplicadas: {len(erro_duplicadas22)}')"
      ],
      "metadata": {
        "id": "PUP7PssSF2Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2349cf9d-c43d-4146-a9d9-f74499591743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['o', 'o', 'onde', 'e', 'foi', 'e', 'e', '14']\n",
            "Capitulo 3: Quantidade de erro de duplicadas: 8\n",
            "['se', 'o']\n",
            "Capitulo 22: Quantidade de erro de duplicadas: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uso incorreto de hifens em palavras compostas\n",
        "padrao_hifens = r'\\b\\w+-{2,}\\w+\\b'\n",
        "\n",
        "# Capitulo 3\n",
        "erro_hifens3 = re.findall(padrao_hifens, text3)\n",
        "\n",
        "print(erro_hifens3)\n",
        "\n",
        "print(f'Capitulo 3: Quantidade de erro de hifens: {len(erro_hifens3)}')\n",
        "\n",
        "# Capitulo 22\n",
        "erro_hifens22 = re.findall(padrao_hifens, text22)\n",
        "\n",
        "print(erro_hifens22)\n",
        "\n",
        "print(f'Capitulo 22: Quantidade de erro de hifens: {len(erro_hifens22)}')"
      ],
      "metadata": {
        "id": "re3-3ykOkczq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac2a1a1b-58de-4560-d026-4b5f5f7d7500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2000--2005', '2000--2005', '1681--1722']\n",
            "Capitulo 3: Quantidade de erro de hifens: 3\n",
            "[]\n",
            "Capitulo 22: Quantidade de erro de hifens: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = set(stopwords.words('portuguese'))\n",
        "\n",
        "\n",
        "# Tokens sem stopwords\n",
        "\n",
        "# Capitulo 3\n",
        "tokens3 = [token.lower() for token in text3.split() if token.lower() not in stopwords]\n",
        "\n",
        "print(tokens3)\n",
        "\n",
        "# Capitulo 22\n",
        "\n",
        "tokens22 = [token.lower() for token in text22.split() if token.lower() not in stopwords]\n",
        "\n",
        "print(tokens22)"
      ],
      "metadata": {
        "id": "igiyLlrJxdL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "corretor = SpellChecker(language = 'pt')\n",
        "\n",
        "# Capitulo 3\n",
        "palavras_corrigidas3 = []\n",
        "\n",
        "for token in tokens3:\n",
        "  palavras_corrigidas3.append(corretor.correction(token))\n",
        "\n",
        "# Capitulo 22\n",
        "palavras_corrigidas22 = []\n",
        "\n",
        "for token in tokens22:\n",
        "  palavras_corrigidas22.append(corretor.correction(token))"
      ],
      "metadata": {
        "id": "jCS0DVsGy8ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capitulo 3: Palavras corrgidas\n",
        "print(palavras_corrigidas3)\n",
        "print(f'Capitulo3: Quantidade de palavras corrigidas: {len(palavras_corrigidas3)}')"
      ],
      "metadata": {
        "id": "TiGxchHU02Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capitlo 22: Palavras corrgidas\n",
        "print(palavras_corrigidas22)\n",
        "print(f'Capitulo22: Quantidade de palavras corrigidas: {len(palavras_corrigidas22)}')"
      ],
      "metadata": {
        "id": "lPoqJpeaxBih"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}